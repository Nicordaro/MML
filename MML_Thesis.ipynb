{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MML_Thesis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoZ5pcg1aQ1/TXn3Fvn1iz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nicordaro/MML/blob/main/MML_Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kdinOfuCREV"
      },
      "source": [
        "###Mathematics in Machine Learning\n",
        "#Tesina\n",
        "Nicol√≤ Cordaro s272145\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I-ba2j5HI0h"
      },
      "source": [
        "###Organize imports and dataset definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4vFQIyHGzyi"
      },
      "source": [
        "!pip install dtreeviz\n",
        "import os\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from dtreeviz.trees import *\n",
        "\n",
        "scoring = make_scorer(f1_score)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "def confmat(y_test,pred):\n",
        "    cf_matrix = confusion_matrix(y_test, pred)\n",
        "    ax = sns.heatmap(cf_matrix, annot=True,  fmt='g', cmap=sns.color_palette(\"ch:start=.2,rot=-.3\", as_cmap=True), xticklabels=[\"benign\",\"malign\"], yticklabels=[\"benign\",\"malign\"]) #notation: \"annot\" not \"annote\"\n",
        "    bottom, top = ax.get_ylim()\n",
        "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "    ax.set(xlabel='True Label', ylabel='Predicted Label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV6Hj6qybgAb"
      },
      "source": [
        "tune = False\r\n",
        "viz = False\r\n",
        "pca_flag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLgakeS9CpN1"
      },
      "source": [
        "# Clone github repository with dataset\n",
        "# deleting if already present(Only for development purposes, colab limitations)\n",
        "!rm -rf MML\n",
        "!rm -rf dataset\n",
        "\n",
        "if not os.path.isdir('./MML'):\n",
        "  !git clone https://github.com/Nicordaro/MML\n",
        "    \n",
        "source_dir = './MML/dataset'\n",
        "target_dir = './dataset'\n",
        "    \n",
        "file_names = os.listdir(source_dir)\n",
        "os.mkdir(target_dir)\n",
        "for file_name in file_names:\n",
        "  print(file_name)\n",
        "  shutil.move(source_dir+\"/\"+file_name, target_dir+\"/\"+file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRhstnsZLnjl",
        "cellView": "both"
      },
      "source": [
        "names = {\"sampcode\":\"Sample code number\", \n",
        "\"clump\": \"Clump Thickness\", \n",
        "\"uni_size\":\"Uniformity of Cell Size\", \n",
        "\"uni_shape\":\"Uniformity of Cell Shape\", \n",
        "\"adhesion\":\"Marginal Adhesion\", \n",
        "\"epith_size\":\"Single Epithelial Cell Size\", \n",
        "\"nuclei\":\"Bare Nuclei\", \n",
        "\"chromatin\":\"Bland Chromatin\", \n",
        "\"nucleoli\":\"Normal Nucleoli\", \n",
        "\"mitoses\":\"Mitoses\", \n",
        "\"class\":\"Class\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VMoPHTWn_9R"
      },
      "source": [
        "dataset_DF = pd.read_csv(target_dir+\"/breast-cancer-wisconsin.data\", names=list(names.keys()))\n",
        "dataset_DF.iloc[:, 10] = dataset_DF.iloc[:, 10].replace(2, \"benign\").replace(4, \"malign\")\n",
        "dataset_DF.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaLxfGuxBguA"
      },
      "source": [
        "# Inspection & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wUYAzcESZag"
      },
      "source": [
        "for col in dataset_DF.iloc[:, 1:].columns:\r\n",
        "  print(\"Attribute '\"+str(col)+\"'\\t contains: \\t\"+str(sorted(dataset_DF[col].unique())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFgiAPjPnvS9"
      },
      "source": [
        "# Non-numerical values are present in the Bare-nuclei feature\n",
        "dataset_DF.isin(['?']).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bTsBHsTn0dn"
      },
      "source": [
        "# searching non-numeric (\"?\") occurrances in the dataset\n",
        "dataset_DF = dataset_DF.drop(dataset_DF[dataset_DF[\"nuclei\"]==\"?\"].index)\n",
        "# conversion to numeric the object column\n",
        "dataset_DF.iloc[:, 6] = pd.to_numeric(dataset_DF.iloc[:, 6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrQQtPR5Udbz"
      },
      "source": [
        "for col in dataset_DF.iloc[:, 1:].columns:\r\n",
        "  print(\"Attribute '\"+str(col)+\"'\\t contains: \\t\"+str(sorted(dataset_DF[col].unique())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdIWQlrR1q1"
      },
      "source": [
        "dataset_DF.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiZcYokTK0nH"
      },
      "source": [
        "dataset_DF.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2qLkkKmQaAg"
      },
      "source": [
        "#Rimozione della feature sampcode, non utile alla fine dell'analisi che si vuole portare avanti\n",
        "dataset_DF = dataset_DF.drop(\"sampcode\", axis=1)\n",
        "dataset_DF.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTI1G2FoMfVh"
      },
      "source": [
        "# Description of only benign cancer occurances in the dataset\n",
        "dataset_DF.loc[dataset_DF['class'] == \"benign\"].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIM-s_rPOFP4"
      },
      "source": [
        "# Description of only malign cancer occurances in the dataset\n",
        "dataset_DF.loc[dataset_DF['class'] == \"malign\"].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlSxNJlTIPHw"
      },
      "source": [
        "encoded = pd.concat([dataset_DF.iloc[:, 0:9], dataset_DF[\"class\"].replace(\"benign\", 0).replace(\"malign\", 1)], axis=1)\n",
        "encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yux5MZdUWUw"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feoY1HfqfQwd"
      },
      "source": [
        "fig, ax1 = plt.subplots(figsize=(20,10), facecolor = \"white\")\n",
        "col_dict = {\"benign\":\"#81c784\", \"malign\": \"#e57373\"}\n",
        "graph = sns.countplot(dataset_DF[\"class\"], palette=col_dict);\n",
        "graph.set_xticklabels(graph.get_xticklabels())\n",
        "for p in graph.patches:\n",
        "    height = p.get_height()\n",
        "    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkTCgCC9P5qd"
      },
      "source": [
        "f,ax = plt.subplots(figsize=(15,15), facecolor=\"white\")\n",
        "mask = np.triu(np.ones_like(encoded.corr(), dtype=bool))\n",
        "sns.heatmap(encoded.corr(), annot=True, linewidths=0.5, fmt='.2f', cmap='Reds', ax=ax, square=True, mask=mask);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3O79uJsRuPH"
      },
      "source": [
        "plt.subplots(3, 3, figsize = (20, 20), facecolor = \"white\")\n",
        "\n",
        "for i, col in enumerate(dataset_DF.columns[:9]):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  sns.histplot(dataset_DF.loc[dataset_DF['class'] == 'benign', col], stat=\"probability\", label='benign', color=\"#81c784\", element=\"bars\", discrete=True, kde=True)\n",
        "  sns.histplot(dataset_DF.loc[dataset_DF['class'] == 'malign', col], stat=\"probability\", label='malign', color=\"#e57373\", element=\"bars\", discrete=True, kde=True)\n",
        "  plt.title(col)\n",
        "  plt.xticks(np.arange(1,10,1))\n",
        "  plt.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKypg7rFQAQq"
      },
      "source": [
        "if viz:\n",
        "  plt.subplots(3, 3, figsize = (20, 20), facecolor = \"white\")\n",
        "  for i, col in enumerate(dataset_DF.columns[:9]):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    sns.swarmplot(y=dataset_DF.iloc[:, i] , x=\"class\", size=2, palette=col_dict, data=dataset_DF);\n",
        "    plt.xlabel(\"Type of Cancer\", size=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfC1CpiFex_Z",
        "cellView": "both"
      },
      "source": [
        "if viz:\n",
        "  sns.set_style(\"ticks\")\n",
        "  sns.pairplot(dataset_DF, hue = \"class\", diag_kind=\"kde\", height=2, palette=col_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NIInQsmUcOS"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5y6Y3_bK4sM"
      },
      "source": [
        "#splitting data and target dataframe\n",
        "x = dataset_DF.reset_index(drop=True)\n",
        "x_unscaled = x\n",
        "seed = 42\n",
        "x_unscaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oml-BNj0dh63"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x.iloc[:, :9])\n",
        "x_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG1TbyQ_tmgO"
      },
      "source": [
        "scaled_DF = pd.DataFrame(data=x_scaled, columns=['clump', 'uni_size', 'uni_shape',\t'adhesion',\t'epith_size',\t'nuclei',\t'chromatin', 'nucleoli',\t'mitoses'])\r\n",
        "scaled_DF_with_labels = pd.concat((scaled_DF ,(dataset_DF.iloc[:, 9].reset_index(drop=True))), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgyuAD4roU1s"
      },
      "source": [
        "scaled_DF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qU4grsEvXOw"
      },
      "source": [
        "plt.figure(figsize=(15,11))\r\n",
        "ax = sns.boxplot(data=scaled_DF_with_labels, palette='colorblind')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYjjmKI4nM2r"
      },
      "source": [
        "x = scaled_DF_with_labels.iloc[:, :9]\r\n",
        "y = scaled_DF_with_labels.iloc[:, 9].replace(\"benign\", 0).replace(\"malign\", 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaG--_t4kMDF"
      },
      "source": [
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(random_state=SEED).fit(x)\n",
        "plt.figure(figsize=(15,11))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.plot(pca.explained_variance_ratio_)\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('proportion of variance explained');\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.grid()\n",
        "plt.legend(['Cumulative Variance', 'Component Variance'])\n",
        "print(np.cumsum(pca.explained_variance_ratio_))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwwSOJj-QIRo"
      },
      "source": [
        "pca = PCA(n_components = 5)\n",
        "x_pca = pca.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwh6SBB7RmRb"
      },
      "source": [
        "x_pca_DF = pd.DataFrame(data=x_pca)\n",
        "x_pca_DF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMliXXCppdqE"
      },
      "source": [
        "#without pca performances are worsened bc\n",
        "#The PCA is a change of variables, using the correlations explained by orthogonal directions.\n",
        "#Removing directions with non-representative corresponding correlation is like removing noise. You will only keep significant data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmvKFZHCqLDF"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5LUBuEMqUPR"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWzF5o0BUgTV"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ILZLBWOs4vF"
      },
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(x, y, test_size=0.30, random_state=SEED,stratify=y)\r\n",
        "if pca_flag:\r\n",
        "  X_train_val, X_test, y_train_val, y_test = train_test_split(x_pca_DF, y, test_size=0.30, random_state=SEED,stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th6GOi5qt23t"
      },
      "source": [
        "final_report = {'LoRe': [], 'DTree': [], 'RF': [], 'KNN': [], 'SVM': []}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urqyn9LAW76e"
      },
      "source": [
        "##Logistic Regression\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2EEevo9voSs"
      },
      "source": [
        "#To avoid overfitting we use KFold Stratified (stratidication given class imbalance)\n",
        "# Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. \n",
        "# In such cases it is recommended to use stratified sampling as implemented in StratifiedKFold and StratifiedShuffleSplit to ensure that relative class frequencies is approximately preserved in each train and validation fold.\n",
        "\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\n",
        "\n",
        "scores = []\n",
        "for train_index, test_index in kf.split(X_train_val,y_train_val):\n",
        "    X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[test_index]\n",
        "    y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[test_index]\n",
        "    \n",
        "    #SMOTE\n",
        "    sm = SMOTE(random_state=SEED)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "    #Classification\n",
        "    loRe = LogisticRegression(solver='liblinear', multi_class='ovr', C=50)\n",
        "    loRe.fit(X_train, y_train)\n",
        "    pred = loRe.predict(X_val)\n",
        "    scores.append(f1_score(pred,y_val))\n",
        "print(f\"mean score {np.mean(scores)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCia_SUjhu0T"
      },
      "source": [
        "# results on the test set\n",
        "clf = LogisticRegression(solver='liblinear', multi_class='ovr', C=50)\n",
        "\n",
        "sm = SMOTE(random_state=SEED)\n",
        "X_res, y_res = sm.fit_resample(X_train_val, y_train_val)\n",
        "clf.fit(X_res,y_res)\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "final_report['LoRe'].append(accuracy_score(pred,y_test))\n",
        "print(f\"Accuracy = {accuracy_score(pred,y_test)}\")\n",
        "final_report['LoRe'].append(f1_score(pred,y_test))\n",
        "print(f\"F1 = {f1_score(pred,y_test)}\")\n",
        "final_report['LoRe'].append(precision_score(pred,y_test))\n",
        "print(f\"Precision = {precision_score(pred,y_test)}\")\n",
        "final_report['LoRe'].append(recall_score(pred,y_test))\n",
        "print(f\"Recall = {recall_score(pred,y_test)}\")\n",
        "plt.figure(figsize=(15,11), )\n",
        "confmat(y_test,pred)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0ulw_u5rJet"
      },
      "source": [
        "if not pca_flag:\r\n",
        "  importance = clf.coef_[0]\r\n",
        "  plt.figure(figsize=(15,11))\r\n",
        "  # summarize feature importance\r\n",
        "  names = ['clump', 'uni_size', 'uni_shape',\t'adhesion',\t'epith_size',\t'nuclei',\t'chromatin', 'nucleoli',\t'mitoses']\r\n",
        "  plt.xticks(range(len(names)), names)\r\n",
        "  for i,v in enumerate(importance):\r\n",
        "    print('Feature: %0d, Score: %.5f' % (i,v))\r\n",
        "  # plot feature importance\r\n",
        "  plt.bar([x for x in range(len(importance))], importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjYRU8UvWrbF"
      },
      "source": [
        "Decision Tree CLF\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FjiL4OXh08P"
      },
      "source": [
        "kf = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\n",
        "\n",
        "scores = []\n",
        "for train_index, test_index in kf.split(X_train_val,y_train_val):\n",
        "    X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[test_index]\n",
        "    y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[test_index]\n",
        "    \n",
        "    #SMOTE\n",
        "    sm = SMOTE(random_state=SEED)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "    \n",
        "    #Classification\n",
        "    dTree = DecisionTreeClassifier(max_depth=3)\n",
        "    dTree.fit(X_train, y_train)\n",
        "    pred = dTree.predict(X_val)\n",
        "    scores.append(f1_score(pred,y_val))\n",
        "print(f\"mean score {np.mean(scores)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo1U7WNgon1U"
      },
      "source": [
        "# results on the test set\n",
        "clf = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "sm = SMOTE(random_state=SEED)\n",
        "X_res, y_res = sm.fit_resample(X_train_val, y_train_val)\n",
        "clf.fit(X_res,y_res)\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "final_report['DTree'].append(accuracy_score(pred,y_test))\n",
        "print(f\"Accuracy = {accuracy_score(pred,y_test)}\")\n",
        "final_report['DTree'].append(f1_score(pred,y_test))\n",
        "print(f\"F1 = {f1_score(pred,y_test)}\")\n",
        "final_report['DTree'].append(precision_score(pred,y_test))\n",
        "print(f\"Precision = {precision_score(pred,y_test)}\")\n",
        "final_report['DTree'].append(recall_score(pred,y_test))\n",
        "print(f\"Recall = {recall_score(pred,y_test)}\")\n",
        "plt.figure(figsize=(15,11))\n",
        "\n",
        "confmat(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm2A-KZnd98a"
      },
      "source": [
        "feature_names = ['clump', 'uni_size', 'uni_shape',\t'adhesion',\t'epith_size',\t'nuclei',\t'chromatin', 'nucleoli',\t'mitoses']\r\n",
        "class_names = ['benign', 'malign']\r\n",
        "\r\n",
        "plt.figure(figsize=(28,43))\r\n",
        "plot_tree(clf, feature_names=feature_names, class_names=class_names)\r\n",
        "#viz = dtreeviz(clf, X_test, pred, target_name=\"target\", feature_nameds=feature_names, class_names=class_names)\r\n",
        "\r\n",
        "#viz\r\n",
        "#viz.save(\"decision_tree.svg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmtBqZkljtOZ"
      },
      "source": [
        "viz = dtreeviz(clf, X_test, pred, target_name=\"target\", feature_names=feature_names, class_names=class_names, orientation='LR', scale=2)\r\n",
        "\r\n",
        "viz.save('decision_tree.svg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrITUruArx9Y"
      },
      "source": [
        "if not pca_flag:\r\n",
        "  importance = clf.feature_importances_\r\n",
        "  plt.figure(figsize=(15,11))\r\n",
        "  names = ['clump', 'uni_size', 'uni_shape',\t'adhesion',\t'epith_size',\t'nuclei',\t'chromatin', 'nucleoli',\t'mitoses']\r\n",
        "  plt.xticks(range(len(names)), names)\r\n",
        "  # summarize feature importance\r\n",
        "  for i,v in enumerate(importance):\r\n",
        "    print('Feature: %0d, Score: %.5f' % (i,v))\r\n",
        "  # plot feature importance\r\n",
        "  plt.bar([x for x in range(len(importance))], importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tal6zKQTUqX"
      },
      "source": [
        "Random Forest CLF\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCCnPJDRLYV"
      },
      "source": [
        "if tune:\r\n",
        "  #List Hyperparameters that we want to tune.\r\n",
        "  estimators_list = [50, 70, 90, 100, 110, 130, 140]\r\n",
        "  features_list = [\"log2\", \"sqrt\", \"auto\"]\r\n",
        "  sample_leafs_list = [2, 4, 8, 10]\r\n",
        "  #Convert to dictionary\r\n",
        "  hyperparameters = dict(n_estimators=estimators_list, max_features=features_list, min_samples_leaf = sample_leafs_list)\r\n",
        "  #Create new KNN object\r\n",
        "  rfc = RandomForestClassifier(max_depth=3, n_jobs=-1)\r\n",
        "  #Use GridSearch\r\n",
        "  clf = GridSearchCV(rfc, hyperparameters, cv=10, n_jobs=-1, scoring = scoring)\r\n",
        "  #Fit the model\r\n",
        "  best_model = clf.fit(x_pca,y)\r\n",
        "  #Print The value of best Hyperparameters\r\n",
        "  print('Best estimator:', best_model.best_estimator_.get_params()['n_estimators'])\r\n",
        "  print('Best feature:', best_model.best_estimator_.get_params()['max_features'])\r\n",
        "  print('Best sample leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm2xKpA3dbJS"
      },
      "source": [
        "#To avoid overfitting we use KFold Stratified (stratidication given class imbalance)\r\n",
        "# Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. \r\n",
        "# In such cases it is recommended to use stratified sampling as implemented in StratifiedKFold and StratifiedShuffleSplit to ensure that relative class frequencies is approximately preserved in each train and validation fold.\r\n",
        "\r\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True)\r\n",
        "\r\n",
        "# StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\r\n",
        "\r\n",
        "scores = []\r\n",
        "for train_index, test_index in kf.split(X_train_val,y_train_val):\r\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\r\n",
        "    X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[test_index]\r\n",
        "    y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[test_index]\r\n",
        "\r\n",
        "    #SMOTE\r\n",
        "    sm = SMOTE(random_state=SEED)\r\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\r\n",
        "    \r\n",
        "    #Classification\r\n",
        "    clf = RandomForestClassifier(max_depth = 3, n_estimators = 90, min_samples_leaf = 10, max_features='sqrt', random_state = SEED, n_jobs=-1)\r\n",
        "    if tune:\r\n",
        "      clf = RandomForestClassifier(max_depth = 3, n_jobs=-1, n_estimators = best_model.best_estimator_.get_params()['n_estimators'], min_samples_leaf = best_model.best_estimator_.get_params()['min_samples_leaf'], max_features=best_model.best_estimator_.get_params()['max_features'], random_state = 42)\r\n",
        "    clf.fit(X_train, y_train)\r\n",
        "    pred = clf.predict(X_val)\r\n",
        "    scores.append(f1_score(pred,y_val))\r\n",
        "print(f\"mean score {np.mean(scores)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "457C-NniS9yl"
      },
      "source": [
        "# results on the test set\r\n",
        "clf = RandomForestClassifier(max_depth = 3, n_estimators = 90, min_samples_leaf = 10, max_features='sqrt', random_state = SEED, n_jobs=-1)\r\n",
        "if tune:\r\n",
        "  clf = RandomForestClassifier(n_estimators = best_model.best_estimator_.get_params()['n_estimators'], min_samples_leaf = best_model.best_estimator_.get_params()['min_samples_leaf'], max_features=best_model.best_estimator_.get_params()['max_features'], random_state = 42)\r\n",
        "\r\n",
        "sm = SMOTE(random_state=SEED)\r\n",
        "X_res, y_res = sm.fit_resample(X_train_val, y_train_val)\r\n",
        "clf.fit(X_res,y_res)\r\n",
        "\r\n",
        "pred = clf.predict(X_test)\r\n",
        "final_report['RF'].append(accuracy_score(pred,y_test))\r\n",
        "print(f\"Accuracy = {accuracy_score(pred,y_test)}\")\r\n",
        "final_report['RF'].append(f1_score(pred,y_test))\r\n",
        "print(f\"F1 = {f1_score(pred,y_test)}\")\r\n",
        "final_report['RF'].append(precision_score(pred,y_test))\r\n",
        "print(f\"Precision = {precision_score(pred,y_test)}\")\r\n",
        "final_report['RF'].append(recall_score(pred,y_test))\r\n",
        "print(f\"Recall = {recall_score(pred,y_test)}\")\r\n",
        "plt.figure(figsize=(15,11))\r\n",
        "confmat(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKjPaXvIrBsg"
      },
      "source": [
        "if not pca_flag:\r\n",
        "  importance = clf.feature_importances_\r\n",
        "  plt.figure(figsize=(15,11))\r\n",
        "  # summarize feature importance\r\n",
        "  names = ['clump', 'uni_size', 'uni_shape',\t'adhesion',\t'epith_size',\t'nuclei',\t'chromatin', 'nucleoli',\t'mitoses']\r\n",
        "  plt.xticks(range(len(names)), names)\r\n",
        "  for i,v in enumerate(importance):\r\n",
        "    print('Feature: %0d, Score: %.5f' % (i,v))\r\n",
        "  # plot feature importance\r\n",
        "  plt.bar([x for x in range(len(importance))], importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbljwxhjXDCn"
      },
      "source": [
        "KNeighbors CLF\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLFv9tp4R8lK"
      },
      "source": [
        "if tune:\n",
        "  #List Hyperparameters that we want to tune.\n",
        "  leaf_size = list(range(1,50))\n",
        "  n_neighbors = list(range(1,30))\n",
        "  algorithm_list = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "  p=[1,2,3]\n",
        "  #Convert to dictionary\n",
        "  hyperparameters = dict(leaf_size=leaf_size, algorithm = algorithm_list, n_neighbors=n_neighbors, p=p)\n",
        "  #Create new KNN object\n",
        "  knn = KNeighborsClassifier()\n",
        "  #Use GridSearch\n",
        "  clf = GridSearchCV(knn, hyperparameters, cv=10, n_jobs=-1, scoring= scoring)\n",
        "  #Fit the model\n",
        "  best_model = clf.fit(x_pca,y)\n",
        "  #Print The value of best Hyperparameters\n",
        "  print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
        "  print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
        "  print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMaVTc6erZTk"
      },
      "source": [
        "#To avoid overfitting we use KFold Stratified (stratidication given class imbalance)\n",
        "# Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. \n",
        "# In such cases it is recommended to use stratified sampling as implemented in StratifiedKFold and StratifiedShuffleSplit to ensure that relative class frequencies is approximately preserved in each train and validation fold.\n",
        "\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\n",
        "\n",
        "scores = []\n",
        "for train_index, test_index in kf.split(X_train_val,y_train_val):\n",
        "    X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[test_index]\n",
        "    y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[test_index]\n",
        "    \n",
        "    #SMOTE\n",
        "    sm = SMOTE(random_state=SEED)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "    \n",
        "    #Classification\n",
        "    knn = KNeighborsClassifier(leaf_size=1, p=1, n_neighbors=15)\n",
        "    if tune:\n",
        "      knn = KNeighborsClassifier(leaf_size=best_model.best_estimator_.get_params()['leaf_size'], p=best_model.best_estimator_.get_params()['p'], n_neighbors=best_model.best_estimator_.get_params()['n_neighbors'])\n",
        "    \n",
        "    knn.fit(X_train, y_train)\n",
        "    pred = knn.predict(X_val)\n",
        "    scores.append(f1_score(pred,y_val))\n",
        "print(f\"mean score {np.mean(scores)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zjr2bq8Q1hQ"
      },
      "source": [
        "# results on the test set\n",
        "clf = KNeighborsClassifier(leaf_size=1, p=1, n_neighbors=15)\n",
        "if tune:\n",
        "  clf = KNeighborsClassifier(leaf_size=best_model.best_estimator_.get_params()['leaf_size'], p=best_model.best_estimator_.get_params()['p'], n_neighbors=best_model.best_estimator_.get_params()['n_neighbors'])\n",
        "\n",
        "sm = SMOTE(random_state=SEED)\n",
        "X_res, y_res = sm.fit_resample(X_train_val, y_train_val)\n",
        "clf.fit(X_res,y_res)\n",
        "\n",
        "pred = knn.predict(X_test)\n",
        "final_report['KNN'].append(accuracy_score(pred,y_test))\n",
        "print(f\"Accuracy = {accuracy_score(pred,y_test)}\")\n",
        "final_report['KNN'].append(f1_score(pred,y_test))\n",
        "print(f\"F1 = {f1_score(pred,y_test)}\")\n",
        "final_report['KNN'].append(precision_score(pred,y_test))\n",
        "print(f\"Precision = {precision_score(pred,y_test)}\")\n",
        "final_report['KNN'].append(recall_score(pred,y_test))\n",
        "print(f\"Recall = {recall_score(pred,y_test)}\")\n",
        "plt.figure(figsize=(15,11))\n",
        "confmat(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x9FRkD_sX0D"
      },
      "source": [
        "if not pca_flag:\r\n",
        "  plt.figure(figsize=(15,11))\r\n",
        "  results = permutation_importance(clf, X_res, y_res, scoring='accuracy')\r\n",
        "  # get importance\r\n",
        "  importance = results.importances_mean\r\n",
        "  names = ['clump', 'uni_size', 'uni_shape',\t'adhesion',\t'epith_size',\t'nuclei',\t'chromatin', 'nucleoli',\t'mitoses']\r\n",
        "  # summarize feature importance\r\n",
        "  for i,v in enumerate(importance):\r\n",
        "    print('Feature: %0d, Score: %.5f' % (i,v))\r\n",
        "  # plot feature importance\r\n",
        "  plt.xticks(range(len(names)), names)\r\n",
        "  plt.bar([x for x in range(len(importance))], importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8bw27PfXJg8"
      },
      "source": [
        "Support Vector Machine CLF\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YHboZWDXPi9"
      },
      "source": [
        "if (tune):\n",
        "  #List Hyperparameters that we want to tune.\n",
        "  C_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  G_list = [0.0001,0.001,0.005,0.01,0.05,0.1,0.5,1,10,100,1000]\n",
        "  kernel_list = ['linear']\n",
        "  #Convert to dictionary\n",
        "  hyperparameters = dict(C=C_list, gamma=G_list, kernel = kernel_list)\n",
        "  #Create new KNN object\n",
        "  svc_CLF = SVC()\n",
        "  #Use GridSearch\n",
        "  clf = GridSearchCV(svc_CLF, hyperparameters, cv=10, n_jobs=-1, scoring = scoring)\n",
        "  #Fit the model\n",
        "  best_model = clf.fit(x_pca,y)\n",
        "  #Print The value of best Hyperparameters\n",
        "  print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
        "  print('Best gamma:', best_model.best_estimator_.get_params()['gamma'])\n",
        "  print('Best kernel:', best_model.best_estimator_.get_params()['kernel'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUJGaMWHTSKd"
      },
      "source": [
        "#To avoid overfitting we use KFold Stratified (stratidication given class imbalance)\n",
        "# Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. \n",
        "# In such cases it is recommended to use stratified sampling as implemented in StratifiedKFold and StratifiedShuffleSplit to ensure that relative class frequencies is approximately preserved in each train and validation fold.\n",
        "\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\n",
        "\n",
        "scores = []\n",
        "for train_index, test_index in kf.split(X_train_val,y_train_val):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[test_index]\n",
        "    y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[test_index]\n",
        "    \n",
        "    #SMOTE\n",
        "    sm = SMOTE(random_state=SEED)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "    \n",
        "    #Classification\n",
        "    clf = SVC(C=1, gamma=0.0001, kernel='linear')\n",
        "    if tune:\n",
        "      clf = SVC(C=best_model.best_estimator_.get_params()['C'], gamma=best_model.best_estimator_.get_params()['gamma'], kernel=best_model.best_estimator_.get_params()['kernel'])\n",
        "    \n",
        "    clf.fit(X_train, y_train)\n",
        "    pred = clf.predict(X_val)\n",
        "    scores.append(f1_score(pred,y_val))\n",
        "print(f\"mean score {np.mean(scores)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrJXrpDcYToS"
      },
      "source": [
        "# results on the test set\n",
        "clf = SVC(C=1, gamma=0.0001, kernel='linear')\n",
        "if tune:\n",
        "  clf = SVC(C=best_model.best_estimator_.get_params()['C'], gamma=best_model.best_estimator_.get_params()['gamma'], kernel=best_model.best_estimator_.get_params()['kernel'])\n",
        "\n",
        "sm = SMOTE(random_state=SEED)\n",
        "X_res, y_res = sm.fit_resample(X_train_val, y_train_val)\n",
        "clf.fit(X_res,y_res)\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "final_report['SVM'].append(accuracy_score(pred,y_test))\n",
        "print(f\"Accuracy = {accuracy_score(pred,y_test)}\")\n",
        "final_report['SVM'].append(f1_score(pred,y_test))\n",
        "print(f\"F1 = {f1_score(pred,y_test)}\")\n",
        "final_report['SVM'].append(precision_score(pred,y_test))\n",
        "print(f\"Precision = {precision_score(pred,y_test)}\")\n",
        "final_report['SVM'].append(recall_score(pred,y_test))\n",
        "print(f\"Recall = {recall_score(pred,y_test)}\")\n",
        "plt.figure(figsize=(15,11))\n",
        "confmat(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrGu0JIJt1j7"
      },
      "source": [
        "if not pca_flag:\r\n",
        "  importance = clf.coef_[0]\r\n",
        "  plt.figure(figsize=(15,11))\r\n",
        "  # summarize feature importance\r\n",
        "  names = ['clump', 'uni_size', 'uni_shape',\t'adhesion',\t'epith_size',\t'nuclei',\t'chromatin', 'nucleoli',\t'mitoses']\r\n",
        "  for i,v in enumerate(importance):\r\n",
        "    print('Feature: %0d, Score: %.5f' % (i,v))\r\n",
        "    plt.xticks(range(len(names)), names)\r\n",
        "    # plot feature importance\r\n",
        "  plt.bar([x for x in range(len(importance))], importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwZn9dHfnTtf"
      },
      "source": [
        "# Final Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pehABiJdukcJ"
      },
      "source": [
        "final_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drgpZ-JRnm1A"
      },
      "source": [
        "accuracies = []\r\n",
        "f1s = []\r\n",
        "precisions = []\r\n",
        "recalls = []\r\n",
        "models = []\r\n",
        "for el in final_report.keys():\r\n",
        "  models.append(el)\r\n",
        "  accuracies.append(final_report[el][0])\r\n",
        "  f1s.append(final_report[el][1])\r\n",
        "  precisions.append(final_report[el][2])\r\n",
        "  recalls.append(final_report[el][3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVVDmaT-petz"
      },
      "source": [
        "scores = pd.DataFrame(list(zip(accuracies, f1s, precisions,recalls)), \r\n",
        "               columns =['accuracy', 'f1', 'precision','recall'], index = models)\r\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dylkQqvdp8_H"
      },
      "source": [
        "for i in ['accuracy', 'f1', 'precision','recall']:\r\n",
        "  plt.figure(figsize=(15,11))\r\n",
        "  ax = sns.barplot(x=models,y=scores[i],palette='icefire')\r\n",
        "  for p in ax.patches:\r\n",
        "    ax.annotate(\"{:.4f}\".format(p.get_height(), 'f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\r\n",
        "  \r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}